{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1NA1g9UyKBNoJKlMw6_QGfWn_vnQkEk8n",
      "authorship_tag": "ABX9TyPWoLXSscKLAcL1QdVoPGdl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dimarsoft/ColabYOLO/blob/main/draw_on_video.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Скачиваем репозиторий https://github.com/dimarsoft/ImageViewerApp.git"
      ],
      "metadata": {
        "id": "IlblSlPZGnNx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone  https://github.com/dimarsoft/ImageViewerApp.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92iZ63WPDyXv",
        "outputId": "7b134a42-a27b-411d-9ce4-bd4fcc921014"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ImageViewerApp'...\n",
            "remote: Enumerating objects: 42, done.\u001b[K\n",
            "remote: Counting objects:   2% (1/42)\u001b[K\rremote: Counting objects:   4% (2/42)\u001b[K\rremote: Counting objects:   7% (3/42)\u001b[K\rremote: Counting objects:   9% (4/42)\u001b[K\rremote: Counting objects:  11% (5/42)\u001b[K\rremote: Counting objects:  14% (6/42)\u001b[K\rremote: Counting objects:  16% (7/42)\u001b[K\rremote: Counting objects:  19% (8/42)\u001b[K\rremote: Counting objects:  21% (9/42)\u001b[K\rremote: Counting objects:  23% (10/42)\u001b[K\rremote: Counting objects:  26% (11/42)\u001b[K\rremote: Counting objects:  28% (12/42)\u001b[K\rremote: Counting objects:  30% (13/42)\u001b[K\rremote: Counting objects:  33% (14/42)\u001b[K\rremote: Counting objects:  35% (15/42)\u001b[K\rremote: Counting objects:  38% (16/42)\u001b[K\rremote: Counting objects:  40% (17/42)\u001b[K\rremote: Counting objects:  42% (18/42)\u001b[K\rremote: Counting objects:  45% (19/42)\u001b[K\rremote: Counting objects:  47% (20/42)\u001b[K\rremote: Counting objects:  50% (21/42)\u001b[K\rremote: Counting objects:  52% (22/42)\u001b[K\rremote: Counting objects:  54% (23/42)\u001b[K\rremote: Counting objects:  57% (24/42)\u001b[K\rremote: Counting objects:  59% (25/42)\u001b[K\rremote: Counting objects:  61% (26/42)\u001b[K\rremote: Counting objects:  64% (27/42)\u001b[K\rremote: Counting objects:  66% (28/42)\u001b[K\rremote: Counting objects:  69% (29/42)\u001b[K\rremote: Counting objects:  71% (30/42)\u001b[K\rremote: Counting objects:  73% (31/42)\u001b[K\rremote: Counting objects:  76% (32/42)\u001b[K\rremote: Counting objects:  78% (33/42)\u001b[K\rremote: Counting objects:  80% (34/42)\u001b[K\rremote: Counting objects:  83% (35/42)\u001b[K\rremote: Counting objects:  85% (36/42)\u001b[K\rremote: Counting objects:  88% (37/42)\u001b[K\rremote: Counting objects:  90% (38/42)\u001b[K\rremote: Counting objects:  92% (39/42)\u001b[K\rremote: Counting objects:  95% (40/42)\u001b[K\rremote: Counting objects:  97% (41/42)\u001b[K\rremote: Counting objects: 100% (42/42)\u001b[K\rremote: Counting objects: 100% (42/42), done.\u001b[K\n",
            "remote: Compressing objects:   3% (1/31)\u001b[K\rremote: Compressing objects:   6% (2/31)\u001b[K\rremote: Compressing objects:   9% (3/31)\u001b[K\rremote: Compressing objects:  12% (4/31)\u001b[K\rremote: Compressing objects:  16% (5/31)\u001b[K\rremote: Compressing objects:  19% (6/31)\u001b[K\rremote: Compressing objects:  22% (7/31)\u001b[K\rremote: Compressing objects:  25% (8/31)\u001b[K\rremote: Compressing objects:  29% (9/31)\u001b[K\rremote: Compressing objects:  32% (10/31)\u001b[K\rremote: Compressing objects:  35% (11/31)\u001b[K\rremote: Compressing objects:  38% (12/31)\u001b[K\rremote: Compressing objects:  41% (13/31)\u001b[K\rremote: Compressing objects:  45% (14/31)\u001b[K\rremote: Compressing objects:  48% (15/31)\u001b[K\rremote: Compressing objects:  51% (16/31)\u001b[K\rremote: Compressing objects:  54% (17/31)\u001b[K\rremote: Compressing objects:  58% (18/31)\u001b[K\rremote: Compressing objects:  61% (19/31)\u001b[K\rremote: Compressing objects:  64% (20/31)\u001b[K\rremote: Compressing objects:  67% (21/31)\u001b[K\rremote: Compressing objects:  70% (22/31)\u001b[K\rremote: Compressing objects:  74% (23/31)\u001b[K\rremote: Compressing objects:  77% (24/31)\u001b[K\rremote: Compressing objects:  80% (25/31)\u001b[K\rremote: Compressing objects:  83% (26/31)\u001b[K\rremote: Compressing objects:  87% (27/31)\u001b[K\rremote: Compressing objects:  90% (28/31)\u001b[K\rremote: Compressing objects:  93% (29/31)\u001b[K\rremote: Compressing objects:  96% (30/31)\u001b[K\rremote: Compressing objects: 100% (31/31)\u001b[K\rremote: Compressing objects: 100% (31/31), done.\u001b[K\n",
            "remote: Total 42 (delta 18), reused 28 (delta 7), pack-reused 0\u001b[K\n",
            "Unpacking objects:   2% (1/42)\rUnpacking objects:   4% (2/42)\rUnpacking objects:   7% (3/42)\rUnpacking objects:   9% (4/42)\rUnpacking objects:  11% (5/42)\rUnpacking objects:  14% (6/42)\rUnpacking objects:  16% (7/42)\rUnpacking objects:  19% (8/42)\rUnpacking objects:  21% (9/42)\rUnpacking objects:  23% (10/42)\rUnpacking objects:  26% (11/42)\rUnpacking objects:  28% (12/42)\rUnpacking objects:  30% (13/42)\rUnpacking objects:  33% (14/42)\rUnpacking objects:  35% (15/42)\rUnpacking objects:  38% (16/42)\rUnpacking objects:  40% (17/42)\rUnpacking objects:  42% (18/42)\rUnpacking objects:  45% (19/42)\rUnpacking objects:  47% (20/42)\rUnpacking objects:  50% (21/42)\rUnpacking objects:  52% (22/42)\rUnpacking objects:  54% (23/42)\rUnpacking objects:  57% (24/42)\rUnpacking objects:  59% (25/42)\rUnpacking objects:  61% (26/42)\rUnpacking objects:  64% (27/42)\rUnpacking objects:  66% (28/42)\rUnpacking objects:  69% (29/42)\rUnpacking objects:  71% (30/42)\rUnpacking objects:  73% (31/42)\rUnpacking objects:  76% (32/42)\rUnpacking objects:  78% (33/42)\rUnpacking objects:  80% (34/42)\rUnpacking objects:  83% (35/42)\rUnpacking objects:  85% (36/42)\rUnpacking objects:  88% (37/42)\rUnpacking objects:  90% (38/42)\rUnpacking objects:  92% (39/42)\rUnpacking objects:  95% (40/42)\rUnpacking objects:  97% (41/42)\rUnpacking objects: 100% (42/42)\rUnpacking objects: 100% (42/42), 13.27 KiB | 1.02 MiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_0pavHoIPW5",
        "outputId": "da2e0d13-ef1f-4e1d-b318-7a588a344235"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drawvideo.py  drive  ImageViewerApp11  Post  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " ('--input', type=str, default='', help='path to input video')\n",
        "\n",
        " ('--output', type=str, default='', help='path to input new video')\n",
        "\n",
        " ('--labels', type=str, default='', help='path to labels folder') они создаются в detect.py с параметром --save.txt"
      ],
      "metadata": {
        "id": "R6nVmPmsCznm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! python /content/ImageViewerApp/drawvideo.py --input \"/content/drive/MyDrive/AI_2023/dataset-v1.1/dataset-v1.1/test/18.mp4\" --output \"/content/Post/18_res2.mp4\" --labels \"/content/drive/MyDrive/dataset-v1.1/labels\""
      ],
      "metadata": {
        "id": "iaKl2m9mB74F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "q3cNbI8tJug7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Или в коде.\n",
        "\n",
        "в run_example() укажите ваши пути"
      ],
      "metadata": {
        "id": "vkLac3mpJeHR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import cv2\n",
        "from enum import Enum\n",
        "import argparse\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class Labels(Enum):\n",
        "    human = 0\n",
        "    helmet = 1\n",
        "    uniform = 2\n",
        "\n",
        "\n",
        "line_a = -0.2\n",
        "line_b = 0.68\n",
        "\n",
        "label_colors = {\n",
        "    Labels.human: (255, 255, 0),\n",
        "    Labels.helmet: (255, 0, 255),\n",
        "    Labels.uniform: (255, 255, 255)\n",
        "}\n",
        "\n",
        "\n",
        "def get_y(x):\n",
        "    return line_a * x + line_b\n",
        "\n",
        "\n",
        "def test_human(label):\n",
        "    y_turniket = get_y(label.x)\n",
        "\n",
        "    if y_turniket > label.y:\n",
        "        label.above = True\n",
        "    else:\n",
        "        label.above = False\n",
        "\n",
        "\n",
        "def parse_row(info):\n",
        "    box = info.split(\" \")\n",
        "    if np.char.isnumeric(box[0].replace('\\n', '')):\n",
        "        return DetectedLabel(Labels(int(box[0])), float(box[1]), float(box[2]), float(box[3]), float(box[4]))\n",
        "\n",
        "    return None\n",
        "\n",
        "\n",
        "def read_labels(labels_file):\n",
        "    labels = []\n",
        "    try:\n",
        "        with open(labels_file, 'r') as handle:\n",
        "            box_info = handle.readlines()\n",
        "            for txt in box_info:\n",
        "                lab = parse_row(txt)\n",
        "                if lab is not None:\n",
        "                    if lab.label is Labels.human:\n",
        "                        test_human(lab)\n",
        "                    labels.append(lab)\n",
        "            return labels\n",
        "    except FileNotFoundError as e:\n",
        "        print(labels_file, e)\n",
        "        return labels\n",
        "    return labels\n",
        "\n",
        "\n",
        "class DetectedLabel:\n",
        "    def __init__(self, label, x, y, width, height):\n",
        "        self.label = label\n",
        "        self.x = x\n",
        "        self.y = y\n",
        "        self.width = width\n",
        "        self.height = height\n",
        "        self.above = None\n",
        "\n",
        "\n",
        "def draw_info(frame, number, frame_w, frame_h, labels_path, suffix):\n",
        "    path_to_file = Path(labels_path) / f\"{suffix}_{number}.txt\"\n",
        "\n",
        "    if path_to_file.exists():\n",
        "        labels = read_labels(path_to_file)\n",
        "\n",
        "        humans = 0\n",
        "\n",
        "        for lab in labels:\n",
        "            hh = int(lab.height * frame_h)\n",
        "            ww = int(lab.width * frame_w)\n",
        "\n",
        "            x = int(lab.x * frame_w - ww / 2)\n",
        "            y = int(lab.y * frame_h - hh / 2)\n",
        "\n",
        "            # турникет\n",
        "            y1 = int(get_y(0) * frame_h)\n",
        "            y2 = int(get_y(1) * frame_h)\n",
        "            cv2.line(frame, (0, y1), (frame_w, y2), (0, 0, 255), 1)\n",
        "\n",
        "            # рамка обекта\n",
        "\n",
        "            cv2.rectangle(frame, (x, y), (x + ww, y + hh), label_colors[lab.label], 1)\n",
        "\n",
        "            # если человек, то рисуем центр масс\n",
        "            if lab.label is Labels.human:\n",
        "                x = int(x + ww / 2)\n",
        "                y = int(y + hh / 2)\n",
        "\n",
        "                if lab.above is True:\n",
        "                    color = (0, 0, 255)\n",
        "                else:\n",
        "                    color = (0, 255, 0)\n",
        "\n",
        "                cv2.circle(frame, (x, y), 10, color, -1)\n",
        "\n",
        "                humans += 1\n",
        "\n",
        "        if humans > 0:\n",
        "            cv2.putText(frame, f\"humans: {humans} \", (0, 40), 0, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
        "\n",
        "    pass\n",
        "\n",
        "\n",
        "def draw_on_video(src_video_path, output_video_path, labels_path):\n",
        "    path_v = Path(src_video_path)\n",
        "    suffix = path_v.stem\n",
        "\n",
        "    # reading the input\n",
        "    input_video = cv2.VideoCapture(src_video_path)\n",
        "\n",
        "    fps = input_video.get(cv2.CAP_PROP_FPS)\n",
        "    w = int(input_video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    h = int(input_video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "    output_video = cv2.VideoWriter(\n",
        "        output_video_path, cv2.VideoWriter_fourcc(*'mp4v'),\n",
        "        fps, (w, h))\n",
        "\n",
        "    frame_id = 0\n",
        "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "\n",
        "    while True:\n",
        "        ret, frame = input_video.read()\n",
        "        if ret:\n",
        "\n",
        "            draw_info(frame, frame_id, w, h, labels_path, suffix)\n",
        "            output_video.write(frame)\n",
        "            # cv2.imshow(\"output\", frame)\n",
        "\n",
        "            frame_id += 1\n",
        "\n",
        "            if cv2.waitKey(1) & 0xFF == ord('s'):\n",
        "                break\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    cv2.destroyAllWindows()\n",
        "    output_video.release()\n",
        "    input_video.release()\n",
        "\n",
        "\n",
        "def draw_folder(input_folder, output_folder, label_folder):\n",
        "    videos_path = Path(input_folder)\n",
        "\n",
        "    # iterate directory\n",
        "    for entry in videos_path.iterdir():\n",
        "        # check if it a file\n",
        "        if entry.is_file() and entry.suffix == \".mp4\":\n",
        "            # print(entry.name, \" \", entry.suffix)\n",
        "\n",
        "            videos_out_path = Path(output_folder) / f\"{entry.stem}_post.mp4\"\n",
        "\n",
        "            print(\"src = \", entry.name, \", output = \", str(videos_out_path))\n",
        "\n",
        "            draw_on_video(str(entry), str(videos_out_path), label_folder)\n",
        "\n",
        "\n",
        "# пример запуска в питоне\n",
        "def run_example():\n",
        "    src_video_path = \"/content/drive/MyDrive/AI_2023/dataset-v1.1/dataset-v1.1/test/18.mp4\"\n",
        "    output_video_path = \"/content/Post/18_3.mp4\"\n",
        "    labels_path = \"/content/drive/MyDrive/dataset-v1.1/labels\"\n",
        "\n",
        "    draw_on_video(src_video_path, output_video_path, labels_path)\n",
        "\n",
        "run_example()\n",
        "\n"
      ],
      "metadata": {
        "id": "mR-eZW37Iphq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Lm20Gui_DJHW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}